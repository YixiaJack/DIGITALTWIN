"""
Streamlit å‰ç«¯ï¼šä¸ä¸åŒåˆ›ä½œæ—¶æœŸçš„â€œè´µå›¾å­â€å¯¹è¯ã€‚
"""

from pathlib import Path
from typing import List, Tuple

import chromadb
import streamlit as st
from openai import OpenAI
from llama_index.core import VectorStoreIndex
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore

from config import PERIODS, require_api_key

BASE_DIR = Path(__file__).parent
CHROMA_DIR = BASE_DIR / "chroma_db"
PERSONA_DIR = BASE_DIR / "personas"


@st.cache_resource(show_spinner=False)
def load_index(period_key: str) -> VectorStoreIndex:
    """ä» ChromaDB åŠ è½½å·²æœ‰ç´¢å¼•ã€‚"""

    period = PERIODS[period_key]
    client = chromadb.PersistentClient(path=str(CHROMA_DIR))
    collection = client.get_or_create_collection(period.collection_name)
    vector_store = ChromaVectorStore(chroma_collection=collection)
    embed_model = OpenAIEmbedding(model="text-embedding-3-small")
    return VectorStoreIndex.from_vector_store(vector_store=vector_store, embed_model=embed_model)


@st.cache_data(show_spinner=False)
def load_persona(period_key: str) -> str:
    """è¯»å–å¯¹åº”æ—¶æœŸçš„äººæ ¼æç¤ºè¯æ–‡ä»¶ã€‚"""

    period = PERIODS[period_key]
    path = PERSONA_DIR / period.persona_file
    if not path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°äººæ ¼æ–‡ä»¶: {path}")
    return path.read_text(encoding="utf-8")


def _format_context(nodes) -> str:
    """å°†æ£€ç´¢èŠ‚ç‚¹æ‹¼æ¥ä¸ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ã€‚"""

    texts: List[str] = []
    for node in nodes:
        if hasattr(node, "node"):
            texts.append(node.node.get_content())
        elif hasattr(node, "get_content"):
            texts.append(node.get_content())
        else:
            texts.append(str(node))
    return "\n\n".join(texts)


def chat_with_artist(
    period_key: str,
    user_question: str,
    chat_history: List[dict],
) -> Tuple[str, List[dict]]:
    """
    æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ä¸ GPT-4o å¯¹è¯ã€‚

    Args:
        period_key: é€‰ä¸­çš„æ—¶æœŸã€‚
        user_question: ç”¨æˆ·é—®é¢˜ã€‚
        chat_history: ç°æœ‰å¯¹è¯å†å²ã€‚

    Returns:
        æ¨¡å‹å›å¤æ–‡æœ¬ä¸æ›´æ–°åçš„å†å²ã€‚
    """

    client = OpenAI(api_key=require_api_key())
    persona = load_persona(period_key)
    index = load_index(period_key)
    retriever = index.as_retriever(similarity_top_k=5)
    retrieved = retriever.retrieve(user_question)
    context_text = _format_context(retrieved)

    system_prompt = (
        f"{persona}\n\n"
        "ä»¥ä¸‹æ˜¯ä¸é—®é¢˜ç›¸å…³çš„èµ„æ–™ç‰‡æ®µï¼Œè¯·ä»¥ç¬¬ä¸€äººç§°ã€ä¸­æ–‡å›ç­”ï¼š\n"
        f"{context_text}"
    )

    history = chat_history[-12:]  # ä»…ä¿ç•™æœ€è¿‘ 6 è½®ï¼ˆ12 æ¡æ¶ˆæ¯ï¼‰
    messages = [{"role": "system", "content": system_prompt}, *history, {"role": "user", "content": user_question}]

    try:
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.6,
        )
    except Exception as exc:  # noqa: BLE001
        raise RuntimeError(f"è°ƒç”¨ OpenAI æ¥å£å¤±è´¥: {exc}") from exc

    reply = completion.choices[0].message.content or ""
    updated_history = [*history, {"role": "user", "content": user_question}, {"role": "assistant", "content": reply}]
    return reply, updated_history[-12:]


def render_chat() -> None:
    """æ„å»º Streamlit UIã€‚"""

    st.set_page_config(page_title="è´µå›¾å­ Â· æ•°å­—åˆ†èº«", page_icon="ğŸ¨")
    st.title("è´µå›¾å­ Â· æ•°å­—åˆ†èº«å¯¹è¯")
    st.caption("é€‰æ‹©ä¸åŒåˆ›ä½œæ—¶æœŸï¼Œä¸é‚£æ—¶çš„â€œæˆ‘â€å¯¹è¯ã€‚")

    period_keys = list(PERIODS.keys())
    default_period = period_keys[0]
    current_period = st.sidebar.radio(
        "é€‰æ‹©æ—¶æœŸ",
        period_keys,
        index=period_keys.index(st.session_state.get("period", default_period)),
        format_func=lambda k: PERIODS[k].name,
    )

    if "period" not in st.session_state or current_period != st.session_state.get("period"):
        st.session_state["chat_history"] = []
    st.session_state["period"] = current_period

    if st.sidebar.button("æ¸…ç©ºå¯¹è¯"):
        st.session_state["chat_history"] = []

    chat_history: List[dict] = st.session_state.get("chat_history", [])
    for message in chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("å‘è‰ºæœ¯å®¶æé—®..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        try:
            reply, new_history = chat_with_artist(current_period, prompt, chat_history)
        except Exception as exc:  # noqa: BLE001
            st.error(str(exc))
            return
        st.session_state["chat_history"] = new_history
        with st.chat_message("assistant"):
            st.markdown(reply)


if __name__ == "__main__":
    render_chat()
